{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37c4fd27",
      "metadata": {
        "id": "37c4fd27"
      },
      "source": [
        "## L'extraction des données du site web"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc30e150",
      "metadata": {
        "id": "dc30e150"
      },
      "source": [
        "### Creation de ma base de données pour son stockage\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ba55de4e",
      "metadata": {
        "id": "ba55de4e"
      },
      "outputs": [],
      "source": [
        "# import sqlite3\n",
        "\n",
        "# # --- Connexion à la base de données ---\n",
        "# conn = sqlite3.connect('books.db')\n",
        "# cursor = conn.cursor()\n",
        "\n",
        "# # --- Création de la table (si elle n'existe pas) ---\n",
        "# cursor.execute('''\n",
        "#     CREATE TABLE IF NOT EXISTS books (\n",
        "#         title TEXT,\n",
        "#         price TEXT,\n",
        "#         Description TEXT\n",
        "#     )''')\n",
        "# conn.commit()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pinecone[grpc]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4jkEcCCRimm",
        "outputId": "209f5705-3b8b-4afc-98ec-c1b781dbe39a"
      },
      "id": "n4jkEcCCRimm",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone[grpc] in /usr/local/lib/python3.11/dist-packages (7.3.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (2025.8.3)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.66.0 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (1.70.0)\n",
            "Requirement already satisfied: grpcio>=1.59.0 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (1.74.0)\n",
            "Collecting lz4>=3.1.3 (from pinecone[grpc])\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (0.0.7)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.29 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (5.29.5)\n",
            "Collecting protoc-gen-openapiv2<0.0.2,>=0.0.1 (from pinecone[grpc])\n",
            "  Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone[grpc]) (2.5.0)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in /usr/local/lib/python3.11/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone[grpc]) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone[grpc]) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone[grpc]) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone[grpc]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone[grpc]) (3.10)\n",
            "Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: lz4, protoc-gen-openapiv2\n",
            "Successfully installed lz4-4.4.4 protoc-gen-openapiv2-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import uuid\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "nwozu74abh0h"
      },
      "id": "nwozu74abh0h",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "pc = Pinecone(api_key=\"pcsk_5d1o81_B9WBR6tFQrcurwSSb9mjmha5qSd4U6LBffk8Ew2pFcYB9tjXi9TTxtdTxVAoN8r\")\n",
        "\n",
        "index_name = \"eeia-1\"\n",
        "pc.delete_index(index_name)\n",
        "if not pc.has_index(index_name):\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        vector_type=\"dense\",\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        ),\n",
        "        deletion_protection=\"disabled\",\n",
        "        tags={\n",
        "            \"environment\": \"development\"\n",
        "        }\n",
        "    )"
      ],
      "metadata": {
        "id": "rbwFDdOGRqpS"
      },
      "id": "rbwFDdOGRqpS",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(sentences)\n",
        "print(type(embeddings))\n",
        "print(embeddings.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7Hfy72mVqFc",
        "outputId": "e54a6c02-094f-4522-feae-75e515f5f7ea"
      },
      "id": "-7Hfy72mVqFc",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    { \"_id\": \"rec1\", \"chunk_text\": \"The Eiffel Tower was completed in 1889 and stands in Paris, France.\", \"category\": \"history\" },\n",
        "    { \"_id\": \"rec2\", \"chunk_text\": \"Photosynthesis allows plants to convert sunlight into energy.\", \"category\": \"science\" },\n",
        "    { \"_id\": \"rec3\", \"chunk_text\": \"Albert Einstein developed the theory of relativity.\", \"category\": \"science\" },\n",
        "    { \"_id\": \"rec4\", \"chunk_text\": \"The mitochondrion is often called the powerhouse of the cell.\", \"category\": \"biology\" },\n",
        "    { \"_id\": \"rec5\", \"chunk_text\": \"Shakespeare wrote many famous plays, including Hamlet and Macbeth.\", \"category\": \"literature\" },\n",
        "    { \"_id\": \"rec6\", \"chunk_text\": \"Water boils at 100°C under standard atmospheric pressure.\", \"category\": \"physics\" },\n",
        "    { \"_id\": \"rec7\", \"chunk_text\": \"The Great Wall of China was built to protect against invasions.\", \"category\": \"history\" },\n",
        "    { \"_id\": \"rec8\", \"chunk_text\": \"Honey never spoils due to its low moisture content and acidity.\", \"category\": \"food science\" },\n",
        "    { \"_id\": \"rec9\", \"chunk_text\": \"The speed of light in a vacuum is approximately 299,792 km/s.\", \"category\": \"physics\" },\n",
        "    { \"_id\": \"rec10\", \"chunk_text\": \"Newton's laws describe the motion of objects.\", \"category\": \"physics\" },\n",
        "    { \"_id\": \"rec11\", \"chunk_text\": \"The human brain has approximately 86 billion neurons.\", \"category\": \"biology\" },\n",
        "    { \"_id\": \"rec12\", \"chunk_text\": \"The Amazon Rainforest is one of the most biodiverse places on Earth.\", \"category\": \"geography\" },\n",
        "    { \"_id\": \"rec13\", \"chunk_text\": \"Black holes have gravitational fields so strong that not even light can escape.\", \"category\": \"astronomy\" },\n",
        "]\n",
        "\n",
        "dense_index = pc.Index(index_name)\n",
        "for text in texts:\n",
        "    print(text)\n",
        "    # Target the index\n",
        "\n",
        "    # Upsert the records into a namespace\n",
        "    dense_index.upsert(vectors=[\n",
        "        {\n",
        "            \"id\": text[\"_id\"],\n",
        "            \"values\": model.encode(text[\"chunk_text\"]).tolist()\n",
        "        }\n",
        "    ])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L9v0ZwgS_zx",
        "outputId": "66c5de87-ef8a-47bf-80f5-85df23e6af77"
      },
      "id": "3L9v0ZwgS_zx",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': 'rec1', 'chunk_text': 'The Eiffel Tower was completed in 1889 and stands in Paris, France.', 'category': 'history'}\n",
            "{'_id': 'rec2', 'chunk_text': 'Photosynthesis allows plants to convert sunlight into energy.', 'category': 'science'}\n",
            "{'_id': 'rec3', 'chunk_text': 'Albert Einstein developed the theory of relativity.', 'category': 'science'}\n",
            "{'_id': 'rec4', 'chunk_text': 'The mitochondrion is often called the powerhouse of the cell.', 'category': 'biology'}\n",
            "{'_id': 'rec5', 'chunk_text': 'Shakespeare wrote many famous plays, including Hamlet and Macbeth.', 'category': 'literature'}\n",
            "{'_id': 'rec6', 'chunk_text': 'Water boils at 100°C under standard atmospheric pressure.', 'category': 'physics'}\n",
            "{'_id': 'rec7', 'chunk_text': 'The Great Wall of China was built to protect against invasions.', 'category': 'history'}\n",
            "{'_id': 'rec8', 'chunk_text': 'Honey never spoils due to its low moisture content and acidity.', 'category': 'food science'}\n",
            "{'_id': 'rec9', 'chunk_text': 'The speed of light in a vacuum is approximately 299,792 km/s.', 'category': 'physics'}\n",
            "{'_id': 'rec10', 'chunk_text': \"Newton's laws describe the motion of objects.\", 'category': 'physics'}\n",
            "{'_id': 'rec11', 'chunk_text': 'The human brain has approximately 86 billion neurons.', 'category': 'biology'}\n",
            "{'_id': 'rec12', 'chunk_text': 'The Amazon Rainforest is one of the most biodiverse places on Earth.', 'category': 'geography'}\n",
            "{'_id': 'rec13', 'chunk_text': 'Black holes have gravitational fields so strong that not even light can escape.', 'category': 'astronomy'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0b58f56",
      "metadata": {
        "id": "a0b58f56"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "base_url = \"https://books.toscrape.com/catalogue/\"\n",
        "page_url = \"category/books_1/index.html\"\n",
        "\n",
        "while page_url:\n",
        "    url = base_url + page_url\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "    for book in books:\n",
        "        href = book.h3.a['href']\n",
        "        book_url = base_url + href.replace('../', '')\n",
        "        book_response = requests.get(book_url)\n",
        "        print(f\"URL du livre: {book_url}\")\n",
        "        print(f\"Statut de la réponse: {book_response.status_code}\")\n",
        "        book_soup = BeautifulSoup(book_response.text, 'html.parser')\n",
        "        print(book_soup.prettify())\n",
        "\n",
        "        title = book_soup.h1.text\n",
        "        price = book_soup.find('p', class_='price_color').text\n",
        "        description = book_soup.find('meta', attrs={'name': 'description'})['content'].strip()\n",
        "        #availability = book_soup.find('p', class_='instock availability').text.strip()\n",
        "        #rating = book_soup.find('p', class_='star-rating')['class'][1]\n",
        "\n",
        "         # --- Insertion des données dans la base de données ---\n",
        "        dense_index.upsert(vectors=[\n",
        "            {\n",
        "                \"id\": str(uuid.uuid4()),\n",
        "                \"values\": model.encode(description).tolist(),\n",
        "                \"metadata\": {\n",
        "                    \"title\": title,\n",
        "                    \"price\": price,\n",
        "                }\n",
        "            }\n",
        "        ])\n",
        "\n",
        "        print(f'Livre inséré : {title}')\n",
        "\n",
        "    next_btn = soup.find('li', class_='next')\n",
        "    if next_btn:\n",
        "        page_url = next_btn.a['href']\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# --- Fermeture de la connexion ---\n",
        "print(\"Scraping terminé. Toutes les données ont été sauvegardées dans books.db.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71acb5f2",
      "metadata": {
        "id": "71acb5f2"
      },
      "source": [
        "## Prétraitement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5906a04f",
      "metadata": {
        "id": "5906a04f",
        "outputId": "3b5e02f7-593a-4c9e-8d6d-aa4dcc2c2b3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame initial :\n",
            "                                   title    price  \\\n",
            "0                   A Light in the Attic  Â£51.77   \n",
            "1                     Tipping the Velvet  Â£53.74   \n",
            "2                             Soumission  Â£50.10   \n",
            "3                          Sharp Objects  Â£47.82   \n",
            "4  Sapiens: A Brief History of Humankind  Â£54.23   \n",
            "\n",
            "                                         Description  \n",
            "0  It's hard to imagine a world without A Light i...  \n",
            "1  \"Erotic and absorbing...Written with starling ...  \n",
            "2  Dans une France assez proche de la nÃ´tre, un ...  \n",
            "3  WICKED above her hipbone, GIRL across her hear...  \n",
            "4  From a renowned historian comes a groundbreaki...  \n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# --- 1. Connexion à la base de données et chargement dans un DataFrame ---\n",
        "# conn = sqlite3.connect('books.db')\n",
        "# query = \"SELECT * FROM books\"\n",
        "# df = pd.read_sql_query(query, conn)\n",
        "# conn.close()\n",
        "\n",
        "# Afficher les 5 premières lignes du DataFrame\n",
        "print(\"DataFrame initial :\")\n",
        "print(df.head())\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# --- 2. Fonctions de prétraitement ---\n",
        "# On va créer une fonction qui regroupe toutes les étapes\n",
        "def preprocess_text(text):\n",
        "    # 1. Normalisation : tout en minuscules\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Nettoyage : suppression de la ponctuation, chiffres, etc.\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # 3. Tokenisation\n",
        "    tokens = word_tokenize(text, language='english')\n",
        "\n",
        "\n",
        "    # 4. Suppression des mots vides\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # On retourne une chaîne de caractères pour faciliter la vectorisation ultérieure\n",
        "    return \" \".join(tokens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d994d5",
      "metadata": {
        "id": "e7d994d5",
        "outputId": "6e034bca-159b-45a2-ea9b-453204ad9426"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame avec les titres prétraités :\n",
            "                             title  price  \\\n",
            "0                      light attic  51.77   \n",
            "1                   tipping velvet  53.74   \n",
            "2                       soumission  50.10   \n",
            "3                    sharp objects  47.82   \n",
            "4  sapiens brief history humankind  54.23   \n",
            "\n",
            "                                         Description  \n",
            "0  hard imagine world without light attic nowclas...  \n",
            "1  erotic absorbingwritten starling powerthe new ...  \n",
            "2  dans une france assez proche de la ntre un hom...  \n",
            "3  wicked hipbone girl across heart words like ro...  \n",
            "4  renowned historian comes groundbreaking narrat...  \n",
            "DataFrame avec les types de données modifiés :\n",
            "title          string[python]\n",
            "price                 float64\n",
            "Description    string[python]\n",
            "dtype: object\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- 3. Application de la fonction à la colonne 'title' ---\n",
        "# On crée une nouvelle colonne 'processed_title' pour stocker les résultats\n",
        "data = df.copy()\n",
        "titre = data.columns\n",
        "for col in titre:\n",
        "    if col in ['title', 'Description']:\n",
        "        data[col] = data[col].apply(preprocess_text)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(\"DataFrame avec les titres prétraités :\")\n",
        "print(data.head())\n",
        "\n",
        "# Changement des types de données\n",
        "# 1. Nettoyage de la colonne 'price'\n",
        "# Remplacer d'abord le caractère d'encodage 'Â' (s'il existe)\n",
        "df['price'] = df['price'].str.replace('Â', '', regex=False)\n",
        "df['price'] = df['price'].str.replace('£', '', regex=False)\n",
        "df['price'] = df['price'].str.replace(',', '.', regex=False) # Remplacer les virgules par des points si nécessaire\n",
        "data['price'] = data['price'].astype(float)\n",
        "data['Description'] = data['Description'].astype('string')\n",
        "data['title'] = data['title'].astype('string')\n",
        "\n",
        "\n",
        "# affichage\n",
        "print(\"DataFrame avec les types de données modifiés :\")\n",
        "print(data.dtypes)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630f278d",
      "metadata": {
        "id": "630f278d"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa41cad",
      "metadata": {
        "id": "0aa41cad"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "# 1. Combinaison des colonnes 'title' et 'Description'\n",
        "data['combined_text'] = data['title'].fillna('') + ' ' + data['Description'].fillna('')\n",
        "\n",
        "# 2. Vectorisation avec TF-IDF\n",
        "# Créer un TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limiter le nombre de features pour l'efficacité\n",
        "\n",
        "# Appliquer le vectoriseur à la nouvelle colonne 'combined_text'\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['combined_text'])\n",
        "\n",
        "# Afficher la taille de la matrice vectorisée\n",
        "# La forme est (nombre de documents, nombre de features)\n",
        "print(\"Matrice TF-IDF pour les titres et descriptions combinés :\")\n",
        "print(tfidf_matrix.shape)\n",
        "\n",
        "# Afficher les 5 premières lignes de la matrice (en format dense pour la lisibilité)\n",
        "print(\"\\nExemple de la matrice TF-IDF (5 premières lignes) :\")\n",
        "print(tfidf_matrix[:20].toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering\n",
        "### 1er test pour le clustering de textes"
      ],
      "metadata": {
        "id": "mYiKzFEkKH3C"
      },
      "id": "mYiKzFEkKH3C"
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "0VbGe6xt7HcY"
      },
      "id": "0VbGe6xt7HcY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = copy.deepcopy(tfidf_matrix)\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    modele_kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
        "    modele_kmeans.fit(X)\n",
        "    # inertia method returns wcss for that model\n",
        "    wcss.append(modele_kmeans.inertia_)"
      ],
      "metadata": {
        "id": "dh33Wpww4_6n"
      },
      "id": "dh33Wpww4_6n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(x = range(1, 11), y = wcss,marker='o',color='red')\n",
        "plt.title('La méthode du coude')\n",
        "plt.xlabel('Nombre de classe')"
      ],
      "metadata": {
        "id": "-BWRZWeHKUXc"
      },
      "id": "-BWRZWeHKUXc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}